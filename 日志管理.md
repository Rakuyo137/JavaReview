日志管理

JVM级别日志

logback log4j

日志的输出格式

过滤的规则,目录的规范

文件的命名 滚动规则 日志容量



集中式日志

 关键步骤：
1、关键日志数据组装，发送到kafka集群（异步）
2、flink消费kafka topic，进行数据的加工
3、flink 写 es stream，并使用es的索引生命周期管理

当然也可以使用其他的集中式日志管理方案。
但我个人更偏向于自己实现，毕竟不难，而且有以下好处：
1、相对于纯日志平台。在flink消费时，可以对数据进行个性化
2、不仅能落es，也能落其他的存储系统，例如hive，方便统计，加个消费者组的事

是日志，也可以是数据存储，也可以是数据告警，取决于你怎么消费。 

![1662965756931](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\1662965756931.png)



![1662965787431](C:\Users\chen\AppData\Roaming\Typora\typora-user-images\1662965787431.png)